{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from warnings import simplefilter\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import *\n",
    "from Trainer import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ANN_Models import *\n",
    "import torch\n",
    "\n",
    "simplefilter(action='ignore', category=pd.errors.ParserWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loss = np.genfromtxt(\"store_loss.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1\n",
      "The device that will be used in training is Quadro P1000\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 1755/2250 [00:08<00:02, 208.40it/s, loss=0.00478]"
     ]
    }
   ],
   "source": [
    "lowest_loss = 100\n",
    "for na in range(5,7):\n",
    "    for nb in range(1,16):\n",
    "        print(na, nb)\n",
    "        data = DATA(na, nb) \n",
    "        Xtrain, Ytrain = data.Xtrain, data.Ytrain\n",
    "        Xval, Yval = data.Xval, data.Yval\n",
    "\n",
    "        # Load data and set them up correctly for dataloader\n",
    "        Dataset_train, Dataset_test = CustomDataset(Xtrain.to_numpy(), Ytrain.to_numpy()).split_data([0.9, 0.1])\n",
    "        Dataset_val = CustomDataset(Xval.to_numpy(), Yval.to_numpy())\n",
    "        #Dataset_test = CustomDataset(data.testsub.u.to_numpy(), data.testsub.th.to_numpy())\n",
    "\n",
    "        dl_train = DataLoader(Dataset_train, batch_size=32, shuffle=True)\n",
    "        dl_val = DataLoader(Dataset_val, batch_size=32, shuffle=False)\n",
    "        dl_test = DataLoader(Dataset_test, batch_size=32, shuffle=True)\n",
    "        model = NARX(5)\n",
    "\n",
    "        train_module = Trainer(model, dl_train, dl_val, dl_test, DIR='savefolderpytorch\\\\NARX')\n",
    "\n",
    "        loss = train_module.fit(epochs=10, batch_size=32, save_log=False)\n",
    "        if loss < lowest_loss:\n",
    "            lowest_loss = loss\n",
    "            best_na = na\n",
    "            best_nb = nb\n",
    "        store_loss[na, nb-1] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(store_loss)\n",
    "plt.title( \"2-D Heat Map\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best na: \", best_na)\n",
    "print(\"best nb: \", best_nb)\n",
    "print(\"lowest loss: \", lowest_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"store_loss.csv\", store_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
