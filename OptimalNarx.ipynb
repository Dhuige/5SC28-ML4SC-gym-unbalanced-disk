{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from warnings import simplefilter\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import *\n",
    "from Trainer import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ANN_Models import *\n",
    "import torch\n",
    "\n",
    "simplefilter(action='ignore', category=pd.errors.ParserWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loss = np.genfromtxt(\"store_loss.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to check what the best na, nb values would be to train on\n",
    "# lowest_loss = 100\n",
    "# for na in range(15,16):\n",
    "#     for nb in range(1,9):\n",
    "#         print(na, nb)\n",
    "#         data = DATA(na, nb) \n",
    "#         Xtrain, Ytrain = data.Xtrain, data.Ytrain\n",
    "#         Xval, Yval = data.Xval, data.Yval\n",
    "\n",
    "#         # Load data and set them up correctly for dataloader\n",
    "#         Dataset_train, Dataset_test = CustomDataset(Xtrain.to_numpy(), Ytrain.to_numpy()).split_data([0.9, 0.1])\n",
    "#         Dataset_val = CustomDataset(Xval.to_numpy(), Yval.to_numpy())\n",
    "#         #Dataset_test = CustomDataset(data.testsub.u.to_numpy(), data.testsub.th.to_numpy())\n",
    "\n",
    "#         dl_train = DataLoader(Dataset_train, batch_size=32, shuffle=True)\n",
    "#         dl_val = DataLoader(Dataset_val, batch_size=32, shuffle=False)\n",
    "#         dl_test = DataLoader(Dataset_test, batch_size=32, shuffle=True)\n",
    "#         model = NARX(5)\n",
    "\n",
    "#         train_module = Trainer(model, dl_train, dl_val, dl_test, DIR='savefolderpytorch\\\\NARX')\n",
    "\n",
    "#         loss = train_module.fit(epochs=10, batch_size=32, save_log=False)\n",
    "#         if loss < lowest_loss:\n",
    "#             lowest_loss = loss\n",
    "#             best_na = na\n",
    "#             best_nb = nb\n",
    "#         store_loss[na, nb-1] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (10, 8)})\n",
    "ax = sns.heatmap(np.log(store_loss), annot=True, linewidths=.5)\n",
    "ax.set(xlabel='nb', ylabel='na')\n",
    "ax.set_xticklabels(np.arange(1, 16))\n",
    "ax.set_title('Log of Loss for different na and nb values')\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.xaxis.set_label_position('top')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (8, 5)})\n",
    "x = np.arange(1, 16)\n",
    "sns.lineplot(x=x, y=store_loss[0, :], label='na=0')\n",
    "sns.lineplot(x=x, y=store_loss[1, :], label='na=1')\n",
    "sns.lineplot(x=x, y=store_loss[2, :], label='na=2')\n",
    "sns.lineplot(x=x, y=store_loss[3, :], label='na=3')\n",
    "sns.lineplot(x=x, y=store_loss[4, :], label='na=4')\n",
    "sns.lineplot(x=x, y=store_loss[5, :], label='na=5')\n",
    "sns.lineplot(x=x, y=store_loss[6, :], label='na=6')\n",
    "sns.lineplot(x=x, y=store_loss[7, :], label='na=7')\n",
    "sns.lineplot(x=x, y=store_loss[8, :], label='na=8')\n",
    "sns.lineplot(x=x, y=store_loss[9, :], label='na=9')\n",
    "sns.lineplot(x=x, y=store_loss[10, :], label='na=10')\n",
    "sns.lineplot(x=x, y=store_loss[11, :], label='na=11')\n",
    "sns.lineplot(x=x, y=store_loss[12, :], label='na=12')\n",
    "sns.lineplot(x=x, y=store_loss[13, :], label='na=13')\n",
    "sns.lineplot(x=x, y=store_loss[14, :], label='na=14')\n",
    "sns.lineplot(x=x, y=store_loss[15, :], label='na=15')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('nb')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for different na and nb values')\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.xticks(np.arange(1, 16))\n",
    "plt.xlim(1, 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 16)\n",
    "sns.lineplot(x=x, y=store_loss[:, 0], label='nb=1')\n",
    "sns.lineplot(x=x, y=store_loss[:, 1], label='nb=2')\n",
    "sns.lineplot(x=x, y=store_loss[:, 2], label='nb=3')\n",
    "sns.lineplot(x=x, y=store_loss[:, 3], label='nb=4')\n",
    "sns.lineplot(x=x, y=store_loss[:, 4], label='nb=5')\n",
    "sns.lineplot(x=x, y=store_loss[:, 5], label='nb=6')\n",
    "sns.lineplot(x=x, y=store_loss[:, 6], label='nb=7')\n",
    "sns.lineplot(x=x, y=store_loss[:, 7], label='nb=8')\n",
    "sns.lineplot(x=x, y=store_loss[:, 8], label='nb=9')\n",
    "sns.lineplot(x=x, y=store_loss[:, 9], label='nb=10')\n",
    "sns.lineplot(x=x, y=store_loss[:, 10], label='nb=11')\n",
    "sns.lineplot(x=x, y=store_loss[:, 11], label='nb=12')\n",
    "sns.lineplot(x=x, y=store_loss[:, 12], label='nb=13')\n",
    "sns.lineplot(x=x, y=store_loss[:, 13], label='nb=14')\n",
    "sns.lineplot(x=x, y=store_loss[:, 14], label='nb=15')\n",
    "plt.xlabel('na')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for different na and nb values')\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.xticks(np.arange(0, 16))\n",
    "plt.xlim(0, 16)\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can say that the optimal lies with nb = 1, and na 9, while the other plot suggest that na = 2, nb 1 be optimal. For this reason it was decided to use na=2, nb 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize size of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loss2_depth = np.genfromtxt(\"store_loss2.csv\", delimiter=',')\n",
    "store = np.genfromtxt(\"store_loss2_withError.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = DATA(2, 1) \n",
    "# Xtrain, Ytrain = data.Xtrain, data.Ytrain\n",
    "# Xval, Yval = data.Xval, data.Yval\n",
    "\n",
    "# additional_loss=[]\n",
    "\n",
    "# # Load data and set them up correctly for dataloader\n",
    "# Dataset_train, Dataset_test = CustomDataset(Xtrain.to_numpy(), Ytrain.to_numpy()).split_data([0.9, 0.1])\n",
    "# Dataset_val = CustomDataset(Xval.to_numpy(), Yval.to_numpy())\n",
    "# #Dataset_test = CustomDataset(data.testsub.u.to_numpy(), data.testsub.th.to_numpy())\n",
    "\n",
    "# dl_train = DataLoader(Dataset_train, batch_size=32, shuffle=True)\n",
    "# dl_val = DataLoader(Dataset_val, batch_size=32, shuffle=False)\n",
    "# dl_test = DataLoader(Dataset_test, batch_size=32, shuffle=True)\n",
    "\n",
    "# for i in range(4):\n",
    "#     model = NARX(5)\n",
    "#     train_module = Trainer(model, dl_train, dl_val, dl_test, DIR='savefolderpytorch\\\\NARX')\n",
    "\n",
    "#     loss = train_module.fit(epochs=10, batch_size=32, save_log=False)\n",
    "#     additional_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x=np.arange(1, 6), y=store[:,0], yerr=store[:,1], fmt='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for different depths')\n",
    "plt.xticks(np.arange(1, 6))\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=[1,2,3,4,5], y=store_loss2_depth, label='Number of hidden layers')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for different number of hidden layers')\n",
    "plt.xlabel('Number of hidden layers')\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.xticks(np.arange(1, 6))\n",
    "plt.xlim(1, 5)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it seems that the number loss increases for layers after 4, I decide to use only 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loss3_outfeatures = np.genfromtxt(\"store_loss3.csv\", delimiter=',')\n",
    "store_loss3_outfeatures2 = np.genfromtxt(\"store_loss3_withError.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = DATA(2, 1) \n",
    "# Xtrain, Ytrain = data.Xtrain, data.Ytrain\n",
    "# Xval, Yval = data.Xval, data.Yval\n",
    "\n",
    "# # Load data and set them up correctly for dataloader\n",
    "# Dataset_train, Dataset_test = CustomDataset(Xtrain.to_numpy(), Ytrain.to_numpy()).split_data([0.9, 0.1])\n",
    "# Dataset_val = CustomDataset(Xval.to_numpy(), Yval.to_numpy())\n",
    "# #Dataset_test = CustomDataset(data.testsub.u.to_numpy(), data.testsub.th.to_numpy())\n",
    "\n",
    "# dl_train = DataLoader(Dataset_train, batch_size=32, shuffle=True)\n",
    "# dl_val = DataLoader(Dataset_val, batch_size=32, shuffle=False)\n",
    "# dl_test = DataLoader(Dataset_test, batch_size=32, shuffle=True)\n",
    "\n",
    "# for i in range(1,11):\n",
    "#     model = NARX(i)\n",
    "\n",
    "#     train_module = Trainer(model, dl_train, dl_val, dl_test, DIR='savefolderpytorch\\\\NARX')\n",
    "\n",
    "#     loss = train_module.fit(epochs=10, batch_size=32, save_log=False)\n",
    "#     store_loss3_outfeatures2[i-1, 4] = loss\n",
    "#     np.savetxt(\"store_loss3_withError.csv\", store_loss3_outfeatures2, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=np.arange(1,11), y=store_loss3_outfeatures, label='Number of output features')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for different number of hidden layer features')\n",
    "plt.xlabel('Number of hidden layer features')\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.xticks(np.arange(1, 11))\n",
    "plt.xlim(1, 10)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loss3_outfeatures2 = np.genfromtxt(\"store_loss3_withError.csv\", delimiter=',')\n",
    "ym = np.mean(store_loss3_outfeatures2, axis=1)\n",
    "ys = np.std(store_loss3_outfeatures2, axis=1)\n",
    "plt.errorbar(x=np.arange(1, 6), y=store[:,0], yerr=store[:,1], fmt='o')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for different depths')\n",
    "plt.xticks(np.arange(1, 6))\n",
    "plt.xlim(0.5, 5.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we find the optimal number of hidden layer nodes being 2. \n",
    "Note that this might not be the optimal solution to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
